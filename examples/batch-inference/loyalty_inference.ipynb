{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "#install(\"awscli==1.22.3\")\n",
    "#install(\"s3fs==2022.01.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 04:20:46.206209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "import sys\n",
    "import os \n",
    "from typing import List\n",
    "from typing import Optional \n",
    "import re\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import xgboost  \n",
    "from tensorflow.keras.models import load_model \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zigbang-mlops/loyalty/',\n",
       " 'zigbang-mlops/loyalty/mean.npy',\n",
       " 'zigbang-mlops/loyalty/model.json',\n",
       " 'zigbang-mlops/loyalty/model_logit.pkl',\n",
       " 'zigbang-mlops/loyalty/model_nn.h5',\n",
       " 'zigbang-mlops/loyalty/model_xgb.json',\n",
       " 'zigbang-mlops/loyalty/std.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem(anon=False, key='****', secret='****')\n",
    "fs.ls(\"s3://zigbang-data/stage/dw_member_loyalty_inference_result/tmpdata\")\n",
    "fs.ls(\"s3://zigbang-mlops/loyalty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter settings required for running a pipeline\n",
    "\n",
    "AWS_KEY = \"*****\"\n",
    "AWS_SECRET = \"*****\"\n",
    "BASE_DATE = \"2022-04-05\"\n",
    "TARGET_DB = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def timer(fn):\n",
    "    from time import perf_counter\n",
    "\n",
    "    def inner(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        to_execute = fn(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "        print('{0} took {1:.8f}s to execute'.format(fn.__name__, execution_time))\n",
    "        return to_execute\n",
    "\n",
    "    return inner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchInput:\n",
    "    base_date: str\n",
    "    target_db: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoyaltyClassifier:\n",
    "    _CONST_MODEL_BUCKET_PATH = \"s3://zigbang-mlops/loyalty\" \n",
    "    _CONST_MODEL_XGB_PATH = \"model/model_xgb.json\"\n",
    "    _CONST_MODEL_LR_PATH = \"model/model_logit.pkl\"\n",
    "    _CONST_MODEL_NN_PATH = \"model/model_nn.h5\"\n",
    "    _CONST_MODEL_MEAN_PATH = \"model/mean.npy\"\n",
    "    _CONST_MODEL_STD_PATH = \"model/std.npy\"\n",
    "\n",
    "    _CONST_BASE_S3_URI = \"s3://zigbang-data/\"\n",
    "    _CONST_DATA_PATH = \"/dw_member_loyalty_feature/\"\n",
    "    _CONST_OUTPUT_PATH = \"/dw_member_loyalty_inference_result\"  \n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self._s3_model_loader()\n",
    "        self.models, self.mean, self.std = self._load_model() \n",
    "             \n",
    "    @timer\n",
    "    def batch_classify(self, input):\n",
    "        df = self._s3_data_loader(input)\n",
    "        feature_list = [f\"f{i}\" for i in range(1,19)] \n",
    " \n",
    "        user_no, X_pred, y_pred = df[\"user_no\"], df[feature_list], np.where(df[\"call_cnt\"]>0, 1, 0)\n",
    "        \n",
    "        # standardization\n",
    "        X_pred -= self.mean\n",
    "        X_pred /= self.std\n",
    "             \n",
    "        d_pred = xgboost.DMatrix(X_pred, label=y_pred)\n",
    "        prob_xgb = self.models['xgb'].predict(d_pred)\n",
    "        prob_lr = self.models['lr'].predict(X_pred)\n",
    "        prob_nn = self.models['nn'].predict(X_pred).flatten()\n",
    "         \n",
    "        result = pd.concat([user_no, X_pred, pd.Series(y_pred, name=\"call\"), \\\n",
    "            pd.Series((prob_xgb+prob_lr+prob_nn)/3, name=\"prob\"), \\\n",
    "            pd.Series(prob_xgb, name=\"prob_xgb\"), pd.Series(prob_lr, name=\"prob_lr\"), \\\n",
    "            pd.Series(prob_nn, name=\"prob_nn\"), df[\"roll_period\"]], axis=1)\n",
    "        # add base date on dag - task2\n",
    "        #result['base_date'] = pd.to_datetime(input.base_date).strftime(\"%Y-%m-%d\") \n",
    "                 \n",
    "        return result \n",
    " \n",
    "    @timer\n",
    "    def _load_model(self): \n",
    "        models = {}\n",
    "        model_xgb = xgboost.Booster()\n",
    "        model_xgb.load_model(self._CONST_MODEL_XGB_PATH)\n",
    "        models['xgb'] = model_xgb\n",
    "\n",
    "        model_lr = pickle.load(open(self._CONST_MODEL_LR_PATH, \"rb\"))\n",
    "        models['lr'] = model_lr\n",
    "\n",
    "        model_nn = load_model(self._CONST_MODEL_NN_PATH)\n",
    "        models['nn'] = model_nn\n",
    "\n",
    "        mean = np.load(self._CONST_MODEL_MEAN_PATH)\n",
    "        std = np.load(self._CONST_MODEL_STD_PATH)\n",
    "        return models, mean, std\n",
    "        \n",
    "    @timer\n",
    "    def _s3_model_loader(self):\n",
    "        fs = s3fs.S3FileSystem(anon=False, key=AWS_KEY, secret=AWS_SECRET) \n",
    "        fs.ls(self._CONST_MODEL_BUCKET_PATH)\n",
    "        fs.download(\"zigbang-mlops/loyalty/model_xgb.json\", self._CONST_MODEL_XGB_PATH)\n",
    "        fs.download(\"zigbang-mlops/loyalty/model_logit.pkl\", self._CONST_MODEL_LR_PATH)\n",
    "        fs.download(\"zigbang-mlops/loyalty/model_nn.h5\", self._CONST_MODEL_NN_PATH)\n",
    "        fs.download(\"zigbang-mlops/loyalty/mean.npy\", self._CONST_MODEL_MEAN_PATH)\n",
    "        fs.download(\"zigbang-mlops/loyalty/std.npy\", self._CONST_MODEL_STD_PATH)\n",
    "\n",
    "    @timer\n",
    "    def _s3_data_loader(self, input):\n",
    "        fs = s3fs.S3FileSystem(anon=False, key=AWS_KEY, secret=AWS_SECRET) \n",
    "        print(\"target url: \", self._CONST_BASE_S3_URI+input.target_db+self._CONST_DATA_PATH)\n",
    "        batch_data = fs.ls(self._CONST_BASE_S3_URI+input.target_db+self._CONST_DATA_PATH, refresh=True)\n",
    "        data = ''\n",
    "\n",
    "        try: \n",
    "            for batch in batch_data:\n",
    "                if bool(re.search(input.base_date, batch)) is True:\n",
    "                    uri = f's3://{batch}'\n",
    "                    data = fs.ls(uri, refresh=True)[0]\n",
    "            if(len(data) == 0):\n",
    "                raise Exception('wrong s3 uri: ', data) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        bucket_uri = f's3://{data}' \n",
    "        df = pq.ParquetDataset(bucket_uri, filesystem=fs).read_pandas().to_pandas()\n",
    "        \n",
    "        return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "block:batch_inference"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_s3_model_loader took 1.08582731s to execute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 04:21:00.624090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-28 04:21:00.624126: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: UNKNOWN ERROR (-1)\n",
      "2022-03-28 04:21:00.624142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kale8g-0): /proc/driver/nvidia/version does not exist\n",
      "2022-03-28 04:21:00.624369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-28 04:21:00.662494: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
      "2022-03-28 04:21:00.662788: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555784a49500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-28 04:21:00.662808: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_load_model took 0.37627557s to execute\n",
      "target url:  s3://zigbang-data/stage/dw_member_loyalty_feature/\n",
      "_s3_data_loader took 2.40398365s to execute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 04:21:28.176477: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 390602448 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_classify took 65.71268230s to execute\n"
     ]
    }
   ],
   "source": [
    "batch_input = BatchInput()\n",
    "batch_input.base_date = BASE_DATE\n",
    "batch_input.target_db = TARGET_DB\n",
    "\n",
    "classifier = LoyaltyClassifier()\n",
    "\n",
    " \n",
    "result = classifier.batch_classify(batch_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "block:show_result",
     "prev:batch_inference"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_no</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>call</th>\n",
       "      <th>prob</th>\n",
       "      <th>prob_xgb</th>\n",
       "      <th>prob_lr</th>\n",
       "      <th>prob_nn</th>\n",
       "      <th>roll_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000887</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>-0.375167</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.160836</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343018</td>\n",
       "      <td>-0.526745</td>\n",
       "      <td>0.235529</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142203</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.334836</td>\n",
       "      <td>0.068605</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005768</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.487006</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.160836</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548881</td>\n",
       "      <td>-0.465996</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.374444</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10008430</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>0.387632</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>-0.487006</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.160836</td>\n",
       "      <td>0.102615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.258135</td>\n",
       "      <td>0.533476</td>\n",
       "      <td>0.484647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>0.413050</td>\n",
       "      <td>0.671630</td>\n",
       "      <td>0.450711</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10009709</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.487006</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.285277</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706306</td>\n",
       "      <td>-0.647029</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125228</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.360146</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010187</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.598846</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.285277</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.921588</td>\n",
       "      <td>-0.729648</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134131</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.363075</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712512</th>\n",
       "      <td>9983054</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.598846</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.285277</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015774</td>\n",
       "      <td>-0.863296</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126174</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.350850</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712513</th>\n",
       "      <td>9987343</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.487006</td>\n",
       "      <td>0.436997</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>-0.223057</td>\n",
       "      <td>-0.081935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445277</td>\n",
       "      <td>-0.600860</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138394</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>0.345934</td>\n",
       "      <td>0.046932</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712514</th>\n",
       "      <td>9988464</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.598846</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.285277</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.963299</td>\n",
       "      <td>-0.772172</td>\n",
       "      <td>-0.261049</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170383</td>\n",
       "      <td>0.092186</td>\n",
       "      <td>0.354473</td>\n",
       "      <td>0.064492</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712515</th>\n",
       "      <td>9989063</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.598846</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.223057</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.957917</td>\n",
       "      <td>-0.842034</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125945</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712516</th>\n",
       "      <td>9992431</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.163458</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.292318</td>\n",
       "      <td>-0.598846</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.204909</td>\n",
       "      <td>-0.285277</td>\n",
       "      <td>-0.266485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508516</td>\n",
       "      <td>-0.639132</td>\n",
       "      <td>-0.459681</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125231</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.353044</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712517 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_no        f1        f2        f3        f4        f5        f6  \\\n",
       "0        10000887 -0.117087 -0.163458 -0.301380  0.020191 -0.375167 -0.106524   \n",
       "1        10005768 -0.117087 -0.163458 -0.301380 -0.292318 -0.487006 -0.106524   \n",
       "2        10008430 -0.117087 -0.163458  0.387632  0.020191 -0.487006  0.980519   \n",
       "3        10009709 -0.117087 -0.163458 -0.301380 -0.292318 -0.487006 -0.106524   \n",
       "4        10010187 -0.117087 -0.163458 -0.301380 -0.292318 -0.598846 -0.106524   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2712512   9983054 -0.117087 -0.163458 -0.301380 -0.292318 -0.598846 -0.106524   \n",
       "2712513   9987343 -0.117087 -0.163458 -0.301380 -0.292318 -0.487006  0.436997   \n",
       "2712514   9988464  0.086430 -0.163458 -0.301380 -0.292318 -0.598846 -0.106524   \n",
       "2712515   9989063 -0.117087 -0.163458 -0.301380 -0.292318 -0.598846 -0.106524   \n",
       "2712516   9992431 -0.117087 -0.163458 -0.301380 -0.292318 -0.598846 -0.106524   \n",
       "\n",
       "               f7        f8        f9  ...       f15       f16       f17  \\\n",
       "0       -0.204909 -0.160836 -0.266485  ... -0.343018 -0.526745  0.235529   \n",
       "1       -0.204909 -0.160836 -0.266485  ... -0.548881 -0.465996 -0.459681   \n",
       "2       -0.204909 -0.160836  0.102615  ...  0.018925  0.258135  0.533476   \n",
       "3       -0.204909 -0.285277 -0.266485  ... -0.706306 -0.647029 -0.459681   \n",
       "4       -0.204909 -0.285277 -0.266485  ... -0.921588 -0.729648 -0.459681   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2712512 -0.204909 -0.285277 -0.266485  ... -1.015774 -0.863296 -0.459681   \n",
       "2712513  0.023918 -0.223057 -0.081935  ... -0.445277 -0.600860 -0.459681   \n",
       "2712514 -0.204909 -0.285277  0.287165  ... -0.963299 -0.772172 -0.261049   \n",
       "2712515 -0.204909 -0.223057 -0.266485  ... -0.957917 -0.842034 -0.459681   \n",
       "2712516 -0.204909 -0.285277 -0.266485  ... -0.508516 -0.639132 -0.459681   \n",
       "\n",
       "              f18  call      prob  prob_xgb   prob_lr   prob_nn  roll_period  \n",
       "0       -0.200286     0  0.142203  0.023167  0.334836  0.068605           30  \n",
       "1       -0.200286     0  0.138044  0.008374  0.374444  0.031312           30  \n",
       "2        0.484647     1  0.511797  0.413050  0.671630  0.450711           30  \n",
       "3       -0.200286     0  0.125228  0.006059  0.360146  0.009480           30  \n",
       "4       -0.200286     0  0.134131  0.009366  0.363075  0.029952           30  \n",
       "...           ...   ...       ...       ...       ...       ...          ...  \n",
       "2712512 -0.200286     0  0.126174  0.007833  0.350850  0.019839            7  \n",
       "2712513 -0.200286     0  0.138394  0.022314  0.345934  0.046932            7  \n",
       "2712514 -0.200286     0  0.170383  0.092186  0.354473  0.064492            7  \n",
       "2712515 -0.200286     0  0.125945  0.009708  0.350088  0.018038            7  \n",
       "2712516 -0.200286     0  0.125231  0.006158  0.353044  0.016492            7  \n",
       "\n",
       "[2712517 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload parquet temp table to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "block:s3_upload",
     "prev:batch_inference"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading tmp table...\n",
      "clean up tmp files...\n",
      "writing tmp table...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(result) \n",
    "    \n",
    "print(\"uploading tmp table...\")\n",
    "fs = s3fs.S3FileSystem(anon=False, key=AWS_KEY, secret=AWS_SECRET) \n",
    "# temp file clean up\n",
    "if(len(fs.ls(\"s3://zigbang-data/\"+batch_input.target_db+\"/dw_member_loyalty_inference_result/tmpdata\")) > 0):\n",
    "    print(\"clean up tmp files...\")\n",
    "    fs.rm(\"s3://zigbang-data/\"+batch_input.target_db+\"/dw_member_loyalty_inference_result/tmpdata\", \"-rf\")\n",
    "print(\"writing tmp table...\")\n",
    "pq.write_to_dataset(table=table, \\\n",
    "    root_path=\"s3://zigbang-data/\"+batch_input.target_db+\"/dw_member_loyalty_inference_result/tmpdata\", filesystem=fs)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "saemaromoon/tf2.1.0-kale:v0.2.0",
   "experiment": {
    "id": "new",
    "name": "airflow-batch"
   },
   "experiment_name": "airflow-batch",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "batch-inference-loyalty",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "storage_class_name": "kf-efs-sc",
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
